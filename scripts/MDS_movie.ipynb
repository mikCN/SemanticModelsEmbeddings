{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8b7a7108-1b11-4ff6-a0f8-6a2d0e950f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\P70070004\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Dependencies\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import time\n",
    "from tqdm import tqdm, tqdm_notebook; tqdm.pandas() # Progress bar\n",
    "from sklearn.metrics import label_ranking_average_precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import params as model_params\n",
    "# Machine Learning\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "import tensorflow_io as tfio\n",
    "\n",
    "#from keras.engine.topology import Layer\n",
    "from tensorflow.keras.layers import Layer\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "import features as features_lib\n",
    "import params as model_params\n",
    "import warnings,sys,os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "if sys.platform == 'darwin':\n",
    "    user_env = os.environ['PWD']\n",
    "elif sys.platform == 'win32':\n",
    "    user_env = os.environ['USERPROFILE']\n",
    "   # model_google = models.KeyedVectors.load_word2vec_format(\n",
    "   # 'C:\\\\Users\\P70070004\\Desktop\\Sound_Ontology_Research\\Data\\GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
    "elif sys.platform == 'linux':\n",
    "    user_env = '/workspace/notebooks/'\n",
    "    \n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "mode = 0\n",
    "if user_env=='/workspace/notebooks/':\n",
    "    project_path = os.path.join(user_env,'Natural-Sound-Analysis','')\n",
    "    data_path = os.path.join(user_env,'Data','')\n",
    "    if mode !=2:\n",
    "        print('loading word2vec model...')\n",
    "    dataframe_path = '/workspace/notebooks/Natural-Sound-Analysis/dataframes/'\n",
    "\n",
    "else:\n",
    "    project_path = os.path.join(user_env,'Desktop','NaturalSoundsAnalysis','Natural-Sound-Analysis','')\n",
    "    data_path = os.path.join(user_env,'Desktop','NaturalSoundsAnalysis','Data','')\n",
    "BATCH_SIZE = 16\n",
    "double_gpu = 0\n",
    "if double_gpu:\n",
    "    GPUS = [\"GPU:0\", \"GPU:1\"]\n",
    "    strategy = tf.distribute.MirroredStrategy( GPUS )\n",
    "    batch_size = BATCH_SIZE * strategy.num_replicas_in_sync\n",
    "    print('Number of devices: %d' % strategy.num_replicas_in_sync) \n",
    "else:\n",
    "    GPUS = ['GPU:0']\n",
    "    batch_size = BATCH_SIZE \n",
    "params = model_params.Params()\n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f7a02cad-d5a7-4c19-abaf-530e0e640047",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wav_16k_mono(filename, idx_frame = None):\n",
    "    file_contents = tf.io.read_file(filename)\n",
    "    wav, sample_rate = tf.audio.decode_wav(\n",
    "        file_contents,\n",
    "        desired_channels=1)\n",
    "    wav = tf.squeeze(wav, axis=-1)\n",
    "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "    wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n",
    "\n",
    "\n",
    "    target_length = 16000 * 5\n",
    "    one_second = 0  # Length of one second of audio at 16kHz for the silence in the beginning\n",
    "    \n",
    "    current_length = tf.shape(wav)[0]\n",
    "\n",
    "    if current_length < target_length - one_second:\n",
    "        initial_padding = one_second\n",
    "        sound_portion_length = current_length\n",
    "        \n",
    "        full_repeats = (target_length - one_second) // sound_portion_length\n",
    "        remainder = (target_length - one_second) % sound_portion_length\n",
    "        \n",
    "        # Repeat the waveform and concatenate the remainder\n",
    "        repeated_wav = tf.tile(wav, [full_repeats])\n",
    "        remainder_wav = wav[:remainder]\n",
    "        wav = tf.concat([repeated_wav, remainder_wav], axis=0)\n",
    "\n",
    "        wav = tf.concat([tf.zeros(one_second, dtype=wav.dtype), wav], axis=0)\n",
    "    else:\n",
    "        if idx_frame is None:\n",
    "            wav = tf.concat([tf.zeros(one_second, dtype=wav.dtype), wav[:16000*5]], axis=0)\n",
    "        else:\n",
    "            start_index = target_length * (idx_frame - 1)\n",
    "            end_index = start_index + target_length\n",
    "            wav = tf.concat([tf.zeros(one_second, dtype=wav.dtype), wav[start_index:end_index]], axis=0)\n",
    "                       \n",
    "            if tf.shape(wav)[0] < target_length + one_second:\n",
    "                padding = target_length + one_second - tf.shape(wav)[0]\n",
    "                wav = tf.concat([wav, tf.zeros(padding, dtype=wav.dtype)], axis=0)\n",
    "    return wav\n",
    "def get_spectrogram_and_label_id(audio, params, idx_silence):\n",
    "    # Convert waveform to log-mel spectrogram patches\n",
    "    features = features_lib.waveform_to_log_mel_spectrogram_patches(audio, params)\n",
    "\n",
    "    return features\n",
    "def buffer_and_select_states(features, buffer_size):\n",
    "    # Initialize an empty tensor to accumulate buffers\n",
    "    output_buffers = tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True)\n",
    "    #print(features.shape[-1])\n",
    "    # Initialize the buffer with zeros\n",
    "    initial_buffer = tf.zeros((buffer_size, features.shape[-1]))\n",
    "\n",
    "    # Define a function to slide the window and update the buffer\n",
    "    def body(i, buffer, ta):\n",
    "        # Update the buffer by sliding the window\n",
    "        new_buffer = tf.concat([buffer[1:], [features[i]]], axis=0)\n",
    "        # Write the updated buffer to TensorArray\n",
    "        ta = ta.write(i, new_buffer)\n",
    "        return i + 1, new_buffer, ta\n",
    "\n",
    "    # Run the loop over all frames\n",
    "    _, _, final_ta = tf.while_loop(\n",
    "        cond=lambda i, *_: i < tf.shape(features)[0],\n",
    "        body=body,\n",
    "        loop_vars=(0, initial_buffer, output_buffers),\n",
    "        parallel_iterations=1  # Ensure correct ordering\n",
    "    )\n",
    "    \n",
    "    # Stack all buffered states\n",
    "    stacked_buffers = final_ta.stack()\n",
    "    \n",
    "    return stacked_buffers\n",
    "def load_and_preprocess_combined(file_path, params, silence_index, idx_frame_train=None):\n",
    "    if idx_frame_train is None:\n",
    "        audio = load_wav_16k_mono(file_path)\n",
    "    else:\n",
    "        audio = load_wav_16k_mono(file_path, idx_frame_train)\n",
    "\n",
    "    spectrogram = get_spectrogram_and_label_id(audio, params, silence_index)\n",
    "    #print(updated_labels)\n",
    "    return spectrogram\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (Input, Conv2D, BatchNormalization, Dropout, MaxPooling2D,\n",
    "                                     GRU, TimeDistributed, Softmax, Dense, Flatten,Permute, Masking, Bidirectional, Lambda)\n",
    "from tensorflow.keras.models import Model\n",
    "class FrequencyAttention(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(FrequencyAttention, self).__init__(**kwargs)\n",
    "        self.softmax = Softmax(axis=2)  # Applying softmax over the frequency dimension\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # This builds a weight vector for the frequency dimension\n",
    "        self.attention_weights = self.add_weight(\n",
    "            shape=(input_shape[2], 1),  # Frequency is the third dimension in input_shape\n",
    "            initializer=\"random_normal\",\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Apply attention across the frequency dimension\n",
    "        # inputs shape: (batch, time, frequency, channels)\n",
    "        # Reduce across the channel to simplify the attention application\n",
    "        reduced = tf.reduce_mean(inputs, axis=-1, keepdims=True)  # Shape: (batch, time, frequency, 1)\n",
    "        # Compute attention scores using a simple dot product (not matrix multiplication)\n",
    "        scores = tf.reduce_sum(reduced * self.attention_weights, axis=2, keepdims=True)  # Shape: (batch, time, 1, 1)\n",
    "        scores = self.softmax(scores)  # Apply softmax to obtain attention scores\n",
    "\n",
    "        # Apply attention weights\n",
    "        attended = inputs * scores  # Broadcasting over the frequency and channel dimensions\n",
    "\n",
    "        return attended\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "def apply_attention_with_permute(x):\n",
    "    # Assuming x has shape (batch, time, height, width, channels)\n",
    "    # and you want to focus attention on the frequency (height or width depending on data)\n",
    "\n",
    "    # Permute dimensions to focus on 'height' or 'width' for attention\n",
    "    # For example, to focus on 'width', permute to bring 'width' as the last dimension before channels\n",
    "    x = Permute((1, 3, 2, 4))(x)  # New shape: (batch, time, width, height, channels)\n",
    "    x = TimeDistributed(FrequencyAttention())(x)\n",
    "    x = Permute((1, 3, 2, 4))(x)  # Revert back to original: (batch, time, height, width, channels)\n",
    "    \n",
    "    return x\n",
    "\n",
    "class GRUAttention(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(GRUAttention, self).__init__(**kwargs)\n",
    "        self.softmax = Softmax(axis=-1)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Assume attention is calculated across the feature dimension\n",
    "        self.attention_weights = self.add_weight(\n",
    "            shape=(input_shape[2], 1),  # input_shape[2] is the feature dimension of the GRU output\n",
    "            initializer=\"random_normal\",\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Applying attention across the feature dimension\n",
    "        x = tf.linalg.matmul(inputs, self.attention_weights)  # [batch_size, timesteps, 1]\n",
    "        x = self.softmax(x)\n",
    "        x = tf.linalg.matmul(inputs, x, transpose_a=True)  # Weighted sum of features across time\n",
    "        return x  # [batch_size, feature_dim, 1]\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        # Returns the same feature dimension with the number of timesteps reduced to 1\n",
    "        return (input_shape[0], input_shape[2], 1)\n",
    "\n",
    "def get_buffered_inputs(wav, params, buffer_sizes):\n",
    "    wav = tf.convert_to_tensor(wav, dtype=tf.float32)\n",
    "    spec = get_spectrogram_and_label_id(wav, params, silence_index)\n",
    "    expected_frames = 498\n",
    "    if spec.shape[0] > expected_frames:\n",
    "        spec = spec[:expected_frames, :]\n",
    "    elif spec.shape[0] < expected_frames:\n",
    "        pad_len = expected_frames - spec.shape[0]\n",
    "        spec = tf.pad(spec, [[0, pad_len], [0, 0]])\n",
    "    return [\n",
    "        np.expand_dims(buffer_and_select_states(spec, buffer_sizes[0]), axis=0),\n",
    "        np.expand_dims(buffer_and_select_states(spec, buffer_sizes[1]), axis=0),\n",
    "        np.expand_dims(buffer_and_select_states(spec, buffer_sizes[2]), axis=0),\n",
    "    ]\n",
    "    \n",
    "#base_path = '/workspace/notebooks/Data/AUD_LSTMCNN_weights/final_model_FromGridSearch/'\n",
    "base_path = \"C:/Users/P70070004/Desktop/NaturalSoundsAnalysis/Data/\"\n",
    "fine_tune_path = base_path + 'finetunedESC50/'\n",
    "dataframe_path = \"C:/Users/P70070004/Desktop/NaturalSoundsAnalysis/Natural-Sound-Analysis/dataframes/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e465474a-b877-446d-b099-afacd7497813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded classes: ['airplane' 'breathing' 'brushing_teeth' 'can_opening' 'car_horn' 'cat'\n",
      " 'chainsaw' 'chirping_birds' 'church_bells' 'clapping' 'clock_alarm'\n",
      " 'clock_tick' 'coughing' 'cow' 'crackling_fire' 'crickets' 'crow'\n",
      " 'crying_baby' 'dog' 'door_wood_creaks' 'door_wood_knock'\n",
      " 'drinking_sipping' 'engine' 'fireworks' 'footsteps' 'frog'\n",
      " 'glass_breaking' 'hand_saw' 'helicopter' 'hen' 'insects'\n",
      " 'keyboard_typing' 'laughing' 'mouse_click' 'pig' 'pouring_water' 'rain'\n",
      " 'rooster' 'sea_waves' 'sheep' 'siren' 'sneezing' 'snoring' 'thunderstorm'\n",
      " 'toilet_flush' 'train' 'vacuum_cleaner' 'washing_machine' 'water_drops'\n",
      " 'wind']\n",
      "Encoded classes: ['airplane' 'breathing' 'brushing_teeth' 'can_opening' 'car_horn' 'cat'\n",
      " 'chainsaw' 'chirping_birds' 'church_bells' 'clapping' 'clock_alarm'\n",
      " 'clock_tick' 'coughing' 'cow' 'crackling_fire' 'crickets' 'crow'\n",
      " 'crying_baby' 'dog' 'door_wood_creaks' 'door_wood_knock'\n",
      " 'drinking_sipping' 'engine' 'fireworks' 'footsteps' 'frog'\n",
      " 'glass_breaking' 'hand_saw' 'helicopter' 'hen' 'insects'\n",
      " 'keyboard_typing' 'laughing' 'mouse_click' 'pig' 'pouring_water' 'rain'\n",
      " 'rooster' 'sea_waves' 'sheep' 'siren' 'sneezing' 'snoring' 'thunderstorm'\n",
      " 'toilet_flush' 'train' 'vacuum_cleaner' 'washing_machine' 'water_drops'\n",
      " 'wind']\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n",
      "\n",
      "Processing model: CRNN_optimised_ESC_2025_248.h5 with buffers: [2, 4, 8]\n",
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model, Model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "predictions_dict = {}\n",
    "\n",
    "# Define model list and corresponding buffer size sets\n",
    "model_buffer_map = {\n",
    "    'CRNN_optimised_ESC_2025_248.h5': [2, 4, 8],\n",
    "    'CRNN_optimised_ESC_2025_52040.h5': [5, 20, 40]\n",
    "}\n",
    "\n",
    "df_eval_sel = pd.read_csv(dataframe_path + 'ESC-50/esc50.csv')\n",
    "train_df = df_eval_sel[df_eval_sel['fold'].isin([1, 2, 3, 4])]\n",
    "test_df = df_eval_sel[df_eval_sel['fold'] == 5]\n",
    "\n",
    "files_train = [data_path + 'ESC-50/audio/' + str(x) for x in train_df['filename']]\n",
    "labels_train = list(train_df['category'])\n",
    "files_test = [data_path + 'ESC-50/audio/' + str(x) for x in test_df['filename']]\n",
    "labels_test = list(test_df['category'])\n",
    "\n",
    "custom_objects = {\n",
    "    'FrequencyAttention': FrequencyAttention,\n",
    "    'GRUAttention': GRUAttention\n",
    "}\n",
    "# One-hot encoding labels\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "encoder.fit(pd.DataFrame(labels_train + labels_test))\n",
    "test_labels = encoder.transform(pd.DataFrame(labels_test))\n",
    "print(\"Encoded classes:\", encoder.categories_[0])\n",
    "\n",
    "params = model_params.Params()\n",
    "params.stft_window_seconds = 0.025\n",
    "\n",
    "silence_index = 0\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "\n",
    "df_eval_sel = pd.read_csv(dataframe_path + 'ESC-50/esc50.csv')\n",
    "\n",
    "# Selecting elements for train and test DataFrames\n",
    "train_df = df_eval_sel[df_eval_sel['fold'].isin([1, 2, 3, 4])]\n",
    "test_df = df_eval_sel[df_eval_sel['fold'] == 5]\n",
    "\n",
    "files_train =list(train_df['filename'])\n",
    "files_train = [data_path+'ESC-50/audio/' + str(x) for x in files_train]  \n",
    "labels_train =list(train_df['category'])\n",
    "\n",
    "files_test =list(test_df['filename'])\n",
    "files_test = [data_path+'ESC-50/audio/' + str(x) for x in files_test]  \n",
    "labels_test = list(test_df['category'])\n",
    "all_labels = labels_train + labels_test\n",
    "\n",
    "labels_list_train = list(all_labels)\n",
    "#label_enc = LabelEncoder()\n",
    "encoder = OneHotEncoder(sparse_output = False)\n",
    "#y_int = label_enc.fit_transform(events)\n",
    "#y_int = y_int.reshape(len(y_int), 1)\n",
    "encoder.fit(pd.DataFrame(labels_list_train))\n",
    "test_labels = encoder.transform(pd.DataFrame(labels_test))\n",
    "print(\"Encoded classes:\", encoder.categories_[0])\n",
    "\n",
    "params = model_params.Params()\n",
    "params.stft_window_seconds = 0.025\n",
    "\n",
    "def load_and_preprocess_combined(file_path, params, silence_index, idx_frame_train=None):\n",
    "    if idx_frame_train is None:\n",
    "        audio = load_wav_16k_mono(file_path)\n",
    "    else:\n",
    "        audio = load_wav_16k_mono(file_path, idx_frame_train)\n",
    "    \n",
    "    spectrogram = get_spectrogram_and_label_id(audio, params, silence_index)\n",
    "    #print(updated_labels)\n",
    "    return spectrogram\n",
    "\n",
    "silence_index = 0\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (files_test, None)).map(\n",
    "        lambda x, z: load_and_preprocess_combined(x, params, silence_index, z)\n",
    "    )\n",
    "\n",
    "\n",
    "model_name, buffer_sizes = next(iter(model_buffer_map.items()))\n",
    "#model_name, buffer_sizes = next(reversed(model_buffer_map.items()))\n",
    "\n",
    "print(f\"\\nProcessing model: {model_name} with buffers: {buffer_sizes}\")\n",
    "# === Load the trained model ===\n",
    "#model_name = 'CRNN_optimised_ESC_2025_248.h5'\n",
    "model_path = fine_tune_path + '/' + model_name\n",
    "model = load_model(model_path, custom_objects=custom_objects)\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c0cf57b9-09f8-43f1-aad9-92b29f48321f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step\n",
      "Processed 0/400 files\n",
      "1/1 [==============================] - 0s 368ms/step\n",
      "1/1 [==============================] - 0s 391ms/step\n",
      "1/1 [==============================] - 0s 394ms/step\n",
      "1/1 [==============================] - 0s 425ms/step\n",
      "1/1 [==============================] - 0s 429ms/step\n",
      "1/1 [==============================] - 0s 377ms/step\n",
      "1/1 [==============================] - 0s 405ms/step\n",
      "1/1 [==============================] - 0s 408ms/step\n",
      "1/1 [==============================] - 0s 422ms/step\n",
      "1/1 [==============================] - 0s 386ms/step\n",
      "1/1 [==============================] - 0s 389ms/step\n",
      "1/1 [==============================] - 0s 392ms/step\n",
      "1/1 [==============================] - 0s 389ms/step\n",
      "1/1 [==============================] - 0s 364ms/step\n",
      "1/1 [==============================] - 0s 401ms/step\n",
      "1/1 [==============================] - 0s 417ms/step\n",
      "1/1 [==============================] - 0s 384ms/step\n",
      "1/1 [==============================] - 0s 388ms/step\n",
      "1/1 [==============================] - 0s 435ms/step\n",
      "1/1 [==============================] - 0s 400ms/step\n",
      "1/1 [==============================] - 0s 372ms/step\n",
      "1/1 [==============================] - 0s 419ms/step\n",
      "1/1 [==============================] - 0s 382ms/step\n",
      "1/1 [==============================] - 0s 411ms/step\n",
      "1/1 [==============================] - 0s 405ms/step\n",
      "1/1 [==============================] - 0s 383ms/step\n",
      "1/1 [==============================] - 0s 423ms/step\n",
      "1/1 [==============================] - 0s 439ms/step\n",
      "1/1 [==============================] - 0s 395ms/step\n",
      "1/1 [==============================] - 0s 415ms/step\n",
      "1/1 [==============================] - 0s 410ms/step\n",
      "1/1 [==============================] - 0s 405ms/step\n",
      "1/1 [==============================] - 0s 402ms/step\n",
      "1/1 [==============================] - 0s 392ms/step\n",
      "1/1 [==============================] - 0s 402ms/step\n",
      "1/1 [==============================] - 0s 401ms/step\n",
      "1/1 [==============================] - 0s 400ms/step\n",
      "1/1 [==============================] - 0s 460ms/step\n",
      "1/1 [==============================] - 0s 403ms/step\n",
      "1/1 [==============================] - 0s 378ms/step\n",
      "1/1 [==============================] - 0s 375ms/step\n",
      "1/1 [==============================] - 0s 407ms/step\n",
      "1/1 [==============================] - 0s 429ms/step\n",
      "1/1 [==============================] - 0s 394ms/step\n",
      "1/1 [==============================] - 0s 440ms/step\n",
      "1/1 [==============================] - 0s 374ms/step\n",
      "1/1 [==============================] - 0s 434ms/step\n",
      "1/1 [==============================] - 0s 356ms/step\n",
      "1/1 [==============================] - 0s 389ms/step\n",
      "1/1 [==============================] - 0s 394ms/step\n",
      "Processed 50/400 files\n",
      "1/1 [==============================] - 0s 414ms/step\n",
      "1/1 [==============================] - 0s 393ms/step\n",
      "1/1 [==============================] - 0s 419ms/step\n",
      "1/1 [==============================] - 0s 397ms/step\n",
      "1/1 [==============================] - 0s 406ms/step\n",
      "1/1 [==============================] - 0s 403ms/step\n",
      "1/1 [==============================] - 0s 426ms/step\n",
      "1/1 [==============================] - 0s 405ms/step\n",
      "1/1 [==============================] - 0s 430ms/step\n",
      "1/1 [==============================] - 0s 403ms/step\n",
      "1/1 [==============================] - 0s 406ms/step\n",
      "1/1 [==============================] - 0s 375ms/step\n",
      "1/1 [==============================] - 0s 395ms/step\n",
      "1/1 [==============================] - 0s 437ms/step\n",
      "1/1 [==============================] - 0s 362ms/step\n",
      "1/1 [==============================] - 0s 381ms/step\n",
      "1/1 [==============================] - 0s 408ms/step\n",
      "1/1 [==============================] - 0s 415ms/step\n",
      "1/1 [==============================] - 0s 425ms/step\n",
      "1/1 [==============================] - 0s 383ms/step\n",
      "1/1 [==============================] - 0s 392ms/step\n",
      "1/1 [==============================] - 0s 386ms/step\n",
      "1/1 [==============================] - 0s 389ms/step\n",
      "1/1 [==============================] - 0s 409ms/step\n",
      "1/1 [==============================] - 0s 388ms/step\n",
      "1/1 [==============================] - 0s 385ms/step\n",
      "1/1 [==============================] - 0s 413ms/step\n",
      "1/1 [==============================] - 0s 373ms/step\n",
      "1/1 [==============================] - 0s 401ms/step\n",
      "1/1 [==============================] - 0s 404ms/step\n",
      "1/1 [==============================] - 0s 396ms/step\n",
      "1/1 [==============================] - 0s 391ms/step\n",
      "1/1 [==============================] - 0s 384ms/step\n",
      "1/1 [==============================] - 0s 423ms/step\n",
      "1/1 [==============================] - 0s 405ms/step\n",
      "1/1 [==============================] - 0s 391ms/step\n",
      "1/1 [==============================] - 0s 377ms/step\n",
      "1/1 [==============================] - 0s 417ms/step\n",
      "1/1 [==============================] - 0s 383ms/step\n",
      "1/1 [==============================] - 0s 402ms/step\n",
      "1/1 [==============================] - 0s 393ms/step\n",
      "1/1 [==============================] - 0s 390ms/step\n",
      "1/1 [==============================] - 0s 381ms/step\n",
      "1/1 [==============================] - 0s 434ms/step\n",
      "1/1 [==============================] - 0s 403ms/step\n",
      "1/1 [==============================] - 0s 397ms/step\n",
      "1/1 [==============================] - 0s 400ms/step\n",
      "1/1 [==============================] - 0s 406ms/step\n",
      "1/1 [==============================] - 0s 389ms/step\n",
      "1/1 [==============================] - 0s 390ms/step\n",
      "Processed 100/400 files\n",
      "1/1 [==============================] - 0s 374ms/step\n",
      "1/1 [==============================] - 0s 429ms/step\n",
      "1/1 [==============================] - 0s 375ms/step\n",
      "1/1 [==============================] - 0s 399ms/step\n",
      "1/1 [==============================] - 0s 385ms/step\n",
      "1/1 [==============================] - 0s 398ms/step\n",
      "1/1 [==============================] - 0s 394ms/step\n",
      "1/1 [==============================] - 0s 411ms/step\n",
      "1/1 [==============================] - 0s 385ms/step\n",
      "1/1 [==============================] - 0s 420ms/step\n",
      "1/1 [==============================] - 0s 402ms/step\n",
      "1/1 [==============================] - 0s 419ms/step\n",
      "1/1 [==============================] - 0s 418ms/step\n",
      "1/1 [==============================] - 0s 428ms/step\n",
      "1/1 [==============================] - 0s 405ms/step\n",
      "1/1 [==============================] - 0s 379ms/step\n",
      "1/1 [==============================] - 0s 422ms/step\n",
      "1/1 [==============================] - 0s 411ms/step\n",
      "1/1 [==============================] - 0s 406ms/step\n",
      "1/1 [==============================] - 0s 412ms/step\n",
      "1/1 [==============================] - 0s 437ms/step\n",
      "1/1 [==============================] - 0s 435ms/step\n",
      "1/1 [==============================] - 0s 409ms/step\n",
      "1/1 [==============================] - 0s 373ms/step\n",
      "1/1 [==============================] - 0s 387ms/step\n",
      "1/1 [==============================] - 0s 388ms/step\n",
      "1/1 [==============================] - 0s 438ms/step\n",
      "1/1 [==============================] - 0s 397ms/step\n",
      "1/1 [==============================] - 0s 432ms/step\n",
      "1/1 [==============================] - 0s 423ms/step\n",
      "1/1 [==============================] - 0s 419ms/step\n",
      "1/1 [==============================] - 0s 435ms/step\n",
      "1/1 [==============================] - 0s 399ms/step\n",
      "1/1 [==============================] - 0s 418ms/step\n",
      "1/1 [==============================] - 0s 436ms/step\n",
      "1/1 [==============================] - 0s 413ms/step\n",
      "1/1 [==============================] - 0s 395ms/step\n",
      "1/1 [==============================] - 0s 374ms/step\n",
      "1/1 [==============================] - 0s 387ms/step\n",
      "1/1 [==============================] - 0s 391ms/step\n",
      "1/1 [==============================] - 0s 426ms/step\n",
      "1/1 [==============================] - 0s 416ms/step\n",
      "1/1 [==============================] - 0s 399ms/step\n",
      "1/1 [==============================] - 0s 396ms/step\n",
      "1/1 [==============================] - 0s 376ms/step\n",
      "1/1 [==============================] - 0s 421ms/step\n",
      "1/1 [==============================] - 0s 410ms/step\n",
      "1/1 [==============================] - 0s 423ms/step\n",
      "1/1 [==============================] - 0s 410ms/step\n",
      "1/1 [==============================] - 0s 407ms/step\n",
      "Processed 150/400 files\n",
      "1/1 [==============================] - 0s 388ms/step\n",
      "1/1 [==============================] - 0s 401ms/step\n",
      "1/1 [==============================] - 0s 430ms/step\n",
      "1/1 [==============================] - 0s 418ms/step\n",
      "1/1 [==============================] - 0s 420ms/step\n",
      "1/1 [==============================] - 0s 415ms/step\n",
      "1/1 [==============================] - 0s 407ms/step\n",
      "1/1 [==============================] - 0s 361ms/step\n",
      "1/1 [==============================] - 0s 392ms/step\n",
      "1/1 [==============================] - 0s 391ms/step\n",
      "1/1 [==============================] - 0s 379ms/step\n",
      "1/1 [==============================] - 0s 405ms/step\n",
      "1/1 [==============================] - 0s 396ms/step\n",
      "1/1 [==============================] - 0s 398ms/step\n",
      "1/1 [==============================] - 0s 385ms/step\n",
      "1/1 [==============================] - 0s 462ms/step\n",
      "1/1 [==============================] - 0s 406ms/step\n",
      "1/1 [==============================] - 0s 416ms/step\n",
      "1/1 [==============================] - 0s 389ms/step\n",
      "1/1 [==============================] - 0s 420ms/step\n",
      "1/1 [==============================] - 0s 414ms/step\n",
      "1/1 [==============================] - 0s 442ms/step\n",
      "1/1 [==============================] - 0s 398ms/step\n",
      "1/1 [==============================] - 0s 421ms/step\n",
      "1/1 [==============================] - 0s 393ms/step\n",
      "1/1 [==============================] - 0s 401ms/step\n",
      "1/1 [==============================] - 0s 435ms/step\n",
      "1/1 [==============================] - 0s 442ms/step\n",
      "1/1 [==============================] - 0s 415ms/step\n",
      "1/1 [==============================] - 0s 446ms/step\n",
      "1/1 [==============================] - 0s 410ms/step\n",
      "1/1 [==============================] - 0s 453ms/step\n",
      "1/1 [==============================] - 0s 410ms/step\n",
      "1/1 [==============================] - 0s 409ms/step\n",
      "1/1 [==============================] - 0s 417ms/step\n",
      "1/1 [==============================] - 0s 383ms/step\n",
      "1/1 [==============================] - 0s 377ms/step\n",
      "1/1 [==============================] - 0s 425ms/step\n",
      "1/1 [==============================] - 0s 419ms/step\n",
      "1/1 [==============================] - 0s 410ms/step\n",
      "1/1 [==============================] - 0s 406ms/step\n",
      "1/1 [==============================] - 0s 419ms/step\n",
      "1/1 [==============================] - 0s 396ms/step\n",
      "1/1 [==============================] - 0s 415ms/step\n",
      "1/1 [==============================] - 0s 357ms/step\n",
      "1/1 [==============================] - 0s 385ms/step\n",
      "1/1 [==============================] - 0s 423ms/step\n",
      "1/1 [==============================] - 0s 408ms/step\n",
      "1/1 [==============================] - 0s 431ms/step\n",
      "1/1 [==============================] - 0s 400ms/step\n",
      "Processed 200/400 files\n",
      "1/1 [==============================] - 0s 391ms/step\n",
      "1/1 [==============================] - 0s 437ms/step\n",
      "1/1 [==============================] - 0s 433ms/step\n",
      "1/1 [==============================] - 0s 438ms/step\n",
      "1/1 [==============================] - 0s 417ms/step\n",
      "1/1 [==============================] - 0s 405ms/step\n",
      "1/1 [==============================] - 0s 393ms/step\n",
      "1/1 [==============================] - 0s 423ms/step\n",
      "1/1 [==============================] - 0s 412ms/step\n",
      "1/1 [==============================] - 0s 391ms/step\n",
      "1/1 [==============================] - 0s 396ms/step\n",
      "1/1 [==============================] - 0s 400ms/step\n",
      "1/1 [==============================] - 0s 447ms/step\n",
      "1/1 [==============================] - 0s 424ms/step\n",
      "1/1 [==============================] - 0s 428ms/step\n",
      "1/1 [==============================] - 0s 405ms/step\n",
      "1/1 [==============================] - 0s 434ms/step\n",
      "1/1 [==============================] - 0s 420ms/step\n",
      "1/1 [==============================] - 0s 416ms/step\n",
      "1/1 [==============================] - 0s 385ms/step\n",
      "1/1 [==============================] - 0s 398ms/step\n",
      "1/1 [==============================] - 0s 440ms/step\n",
      "1/1 [==============================] - 0s 415ms/step\n",
      "1/1 [==============================] - 0s 430ms/step\n",
      "1/1 [==============================] - 0s 395ms/step\n",
      "1/1 [==============================] - 0s 451ms/step\n",
      "1/1 [==============================] - 0s 381ms/step\n",
      "1/1 [==============================] - 0s 401ms/step\n",
      "1/1 [==============================] - 0s 404ms/step\n",
      "1/1 [==============================] - 0s 388ms/step\n",
      "1/1 [==============================] - 0s 407ms/step\n",
      "1/1 [==============================] - 0s 416ms/step\n",
      "1/1 [==============================] - 0s 409ms/step\n",
      "1/1 [==============================] - 0s 412ms/step\n",
      "1/1 [==============================] - 0s 413ms/step\n",
      "1/1 [==============================] - 0s 441ms/step\n",
      "1/1 [==============================] - 0s 410ms/step\n",
      "1/1 [==============================] - 0s 422ms/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "1/1 [==============================] - 0s 419ms/step\n",
      "1/1 [==============================] - 0s 398ms/step\n",
      "1/1 [==============================] - 0s 410ms/step\n",
      "1/1 [==============================] - 0s 392ms/step\n",
      "1/1 [==============================] - 0s 426ms/step\n",
      "1/1 [==============================] - 0s 399ms/step\n",
      "1/1 [==============================] - 0s 439ms/step\n",
      "1/1 [==============================] - 0s 422ms/step\n",
      "1/1 [==============================] - 0s 386ms/step\n",
      "1/1 [==============================] - 0s 398ms/step\n",
      "1/1 [==============================] - 0s 437ms/step\n",
      "Processed 250/400 files\n",
      "1/1 [==============================] - 0s 443ms/step\n",
      "1/1 [==============================] - 0s 417ms/step\n",
      "1/1 [==============================] - 0s 385ms/step\n",
      "1/1 [==============================] - 0s 424ms/step\n",
      "1/1 [==============================] - 0s 457ms/step\n",
      "1/1 [==============================] - 0s 411ms/step\n",
      "1/1 [==============================] - 0s 400ms/step\n",
      "1/1 [==============================] - 0s 426ms/step\n",
      "1/1 [==============================] - 0s 406ms/step\n",
      "1/1 [==============================] - 0s 419ms/step\n",
      "1/1 [==============================] - 0s 420ms/step\n",
      "1/1 [==============================] - 0s 430ms/step\n",
      "1/1 [==============================] - 0s 396ms/step\n",
      "1/1 [==============================] - 0s 395ms/step\n",
      "1/1 [==============================] - 0s 418ms/step\n",
      "1/1 [==============================] - 0s 361ms/step\n",
      "1/1 [==============================] - 0s 418ms/step\n",
      "1/1 [==============================] - 0s 397ms/step\n",
      "1/1 [==============================] - 0s 398ms/step\n",
      "1/1 [==============================] - 0s 427ms/step\n",
      "1/1 [==============================] - 0s 423ms/step\n",
      "1/1 [==============================] - 0s 418ms/step\n",
      "1/1 [==============================] - 0s 423ms/step\n",
      "1/1 [==============================] - 0s 405ms/step\n",
      "1/1 [==============================] - 0s 435ms/step\n",
      "1/1 [==============================] - 0s 406ms/step\n",
      "1/1 [==============================] - 0s 407ms/step\n",
      "1/1 [==============================] - 0s 391ms/step\n",
      "1/1 [==============================] - 0s 411ms/step\n",
      "1/1 [==============================] - 0s 411ms/step\n",
      "1/1 [==============================] - 0s 388ms/step\n",
      "1/1 [==============================] - 0s 420ms/step\n",
      "1/1 [==============================] - 0s 408ms/step\n",
      "1/1 [==============================] - 0s 398ms/step\n",
      "1/1 [==============================] - 0s 436ms/step\n",
      "1/1 [==============================] - 0s 436ms/step\n",
      "1/1 [==============================] - 0s 407ms/step\n",
      "1/1 [==============================] - 0s 433ms/step\n",
      "1/1 [==============================] - 0s 415ms/step\n",
      "1/1 [==============================] - 0s 428ms/step\n",
      "1/1 [==============================] - 0s 437ms/step\n",
      "1/1 [==============================] - 0s 412ms/step\n",
      "1/1 [==============================] - 0s 409ms/step\n",
      "1/1 [==============================] - 0s 426ms/step\n",
      "1/1 [==============================] - 0s 405ms/step\n",
      "1/1 [==============================] - 0s 416ms/step\n",
      "1/1 [==============================] - 0s 406ms/step\n",
      "1/1 [==============================] - 0s 412ms/step\n",
      "1/1 [==============================] - 0s 408ms/step\n",
      "1/1 [==============================] - 0s 434ms/step\n",
      "Processed 300/400 files\n",
      "1/1 [==============================] - 0s 388ms/step\n",
      "1/1 [==============================] - 0s 376ms/step\n",
      "1/1 [==============================] - 0s 411ms/step\n",
      "1/1 [==============================] - 0s 396ms/step\n",
      "1/1 [==============================] - 0s 410ms/step\n",
      "1/1 [==============================] - 0s 439ms/step\n",
      "1/1 [==============================] - 0s 409ms/step\n",
      "1/1 [==============================] - 0s 383ms/step\n",
      "1/1 [==============================] - 0s 431ms/step\n",
      "1/1 [==============================] - 0s 406ms/step\n",
      "1/1 [==============================] - 0s 416ms/step\n",
      "1/1 [==============================] - 0s 387ms/step\n",
      "1/1 [==============================] - 0s 424ms/step\n",
      "1/1 [==============================] - 0s 416ms/step\n",
      "1/1 [==============================] - 0s 430ms/step\n",
      "1/1 [==============================] - 0s 412ms/step\n",
      "1/1 [==============================] - 0s 390ms/step\n",
      "1/1 [==============================] - 0s 440ms/step\n",
      "1/1 [==============================] - 0s 403ms/step\n",
      "1/1 [==============================] - 0s 389ms/step\n",
      "1/1 [==============================] - 0s 422ms/step\n",
      "1/1 [==============================] - 0s 424ms/step\n",
      "1/1 [==============================] - 0s 398ms/step\n",
      "1/1 [==============================] - 0s 365ms/step\n",
      "1/1 [==============================] - 0s 395ms/step\n",
      "1/1 [==============================] - 0s 414ms/step\n",
      "1/1 [==============================] - 0s 387ms/step\n",
      "1/1 [==============================] - 0s 407ms/step\n",
      "1/1 [==============================] - 0s 395ms/step\n",
      "1/1 [==============================] - 0s 433ms/step\n",
      "1/1 [==============================] - 0s 407ms/step\n",
      "1/1 [==============================] - 0s 402ms/step\n",
      "1/1 [==============================] - 0s 397ms/step\n",
      "1/1 [==============================] - 0s 412ms/step\n",
      "1/1 [==============================] - 0s 393ms/step\n",
      "1/1 [==============================] - 0s 418ms/step\n",
      "1/1 [==============================] - 0s 417ms/step\n",
      "1/1 [==============================] - 0s 404ms/step\n",
      "1/1 [==============================] - 0s 401ms/step\n",
      "1/1 [==============================] - 0s 436ms/step\n",
      "1/1 [==============================] - 0s 383ms/step\n",
      "1/1 [==============================] - 0s 394ms/step\n",
      "1/1 [==============================] - 0s 417ms/step\n",
      "1/1 [==============================] - 0s 399ms/step\n",
      "1/1 [==============================] - 0s 406ms/step\n",
      "1/1 [==============================] - 0s 410ms/step\n",
      "1/1 [==============================] - 0s 450ms/step\n",
      "1/1 [==============================] - 0s 428ms/step\n",
      "1/1 [==============================] - 0s 398ms/step\n",
      "1/1 [==============================] - 0s 417ms/step\n",
      "Processed 350/400 files\n",
      "1/1 [==============================] - 0s 375ms/step\n",
      "1/1 [==============================] - 0s 406ms/step\n",
      "1/1 [==============================] - 0s 420ms/step\n",
      "1/1 [==============================] - 0s 386ms/step\n",
      "1/1 [==============================] - 0s 384ms/step\n",
      "1/1 [==============================] - 0s 385ms/step\n",
      "1/1 [==============================] - 0s 405ms/step\n",
      "1/1 [==============================] - 0s 391ms/step\n",
      "1/1 [==============================] - 0s 376ms/step\n",
      "1/1 [==============================] - 0s 418ms/step\n",
      "1/1 [==============================] - 0s 400ms/step\n",
      "1/1 [==============================] - 0s 391ms/step\n",
      "1/1 [==============================] - 0s 385ms/step\n",
      "1/1 [==============================] - 0s 399ms/step\n",
      "1/1 [==============================] - 0s 409ms/step\n",
      "1/1 [==============================] - 0s 396ms/step\n",
      "1/1 [==============================] - 0s 426ms/step\n",
      "1/1 [==============================] - 0s 403ms/step\n",
      "1/1 [==============================] - 0s 399ms/step\n",
      "1/1 [==============================] - 0s 404ms/step\n",
      "1/1 [==============================] - 0s 426ms/step\n",
      "1/1 [==============================] - 0s 415ms/step\n",
      "1/1 [==============================] - 0s 390ms/step\n",
      "1/1 [==============================] - 0s 380ms/step\n",
      "1/1 [==============================] - 0s 428ms/step\n",
      "1/1 [==============================] - 0s 409ms/step\n",
      "1/1 [==============================] - 0s 388ms/step\n",
      "1/1 [==============================] - 0s 417ms/step\n",
      "1/1 [==============================] - 0s 428ms/step\n",
      "1/1 [==============================] - 0s 394ms/step\n",
      "1/1 [==============================] - 0s 364ms/step\n",
      "1/1 [==============================] - 0s 433ms/step\n",
      "1/1 [==============================] - 0s 384ms/step\n",
      "1/1 [==============================] - 0s 421ms/step\n",
      "1/1 [==============================] - 0s 359ms/step\n",
      "1/1 [==============================] - 0s 411ms/step\n",
      "1/1 [==============================] - 0s 391ms/step\n",
      "1/1 [==============================] - 0s 423ms/step\n",
      "1/1 [==============================] - 0s 398ms/step\n",
      "1/1 [==============================] - 0s 403ms/step\n",
      "1/1 [==============================] - 0s 378ms/step\n",
      "1/1 [==============================] - 0s 400ms/step\n",
      "1/1 [==============================] - 0s 394ms/step\n",
      "1/1 [==============================] - 0s 399ms/step\n",
      "1/1 [==============================] - 0s 409ms/step\n",
      "1/1 [==============================] - 0s 382ms/step\n",
      "1/1 [==============================] - 0s 392ms/step\n",
      "1/1 [==============================] - 0s 386ms/step\n",
      "1/1 [==============================] - 0s 386ms/step\n",
      "✅ Done. Embeddings shape: (400, 498, 50)\n"
     ]
    }
   ],
   "source": [
    "# === Choose the layer name you want to extract from ===\n",
    "#target_layer_name = 'concatenate_streams'  # exact name\n",
    "\n",
    "target_layer_name = 'dense_2' \n",
    "# === Create a model that outputs embeddings from that layer ===\n",
    "embedding_model = Model(inputs=model.inputs,\n",
    "                        outputs=model.get_layer(target_layer_name).output)\n",
    "\n",
    "n_sounds = 400\n",
    "\n",
    "for i, file in enumerate(files_test):\n",
    "    wav = load_wav_16k_mono(file)\n",
    "    inputs = get_buffered_inputs(wav, params, buffer_sizes=buffer_sizes)\n",
    "    emb = embedding_model.predict(inputs)[0]  # shape: [T, D]\n",
    "    \n",
    "    # allocate shape dynamically on first iteration\n",
    "    if i == 0:\n",
    "        T, D = emb.shape\n",
    "        embeddings_all_sounds = np.zeros((n_sounds, T, D))\n",
    "        \n",
    "    embeddings_all_sounds[i] = emb\n",
    "    \n",
    "    if i % 50 == 0:\n",
    "        print(f\"Processed {i}/{n_sounds} files\")\n",
    "\n",
    "print(\"✅ Done. Embeddings shape:\", embeddings_all_sounds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bb0fd41d-7b58-474d-a395-3509e9d27f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>filename</th>\n",
       "      <th>fold</th>\n",
       "      <th>target</th>\n",
       "      <th>category</th>\n",
       "      <th>esc10</th>\n",
       "      <th>src_file</th>\n",
       "      <th>take</th>\n",
       "      <th>event_type</th>\n",
       "      <th>superclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1600</td>\n",
       "      <td>5-103415-A-2.wav</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>pig</td>\n",
       "      <td>False</td>\n",
       "      <td>103415</td>\n",
       "      <td>A</td>\n",
       "      <td>Mid</td>\n",
       "      <td>Animals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1601</td>\n",
       "      <td>5-103416-A-2.wav</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>pig</td>\n",
       "      <td>False</td>\n",
       "      <td>103416</td>\n",
       "      <td>A</td>\n",
       "      <td>Mid</td>\n",
       "      <td>Animals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1602</td>\n",
       "      <td>5-103418-A-2.wav</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>pig</td>\n",
       "      <td>False</td>\n",
       "      <td>103418</td>\n",
       "      <td>A</td>\n",
       "      <td>Mid</td>\n",
       "      <td>Animals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1603</td>\n",
       "      <td>5-103420-A-2.wav</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>pig</td>\n",
       "      <td>False</td>\n",
       "      <td>103420</td>\n",
       "      <td>A</td>\n",
       "      <td>Mid</td>\n",
       "      <td>Animals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1604</td>\n",
       "      <td>5-103421-A-2.wav</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>pig</td>\n",
       "      <td>False</td>\n",
       "      <td>103421</td>\n",
       "      <td>A</td>\n",
       "      <td>Mid</td>\n",
       "      <td>Animals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>1995</td>\n",
       "      <td>5-263831-B-6.wav</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>hen</td>\n",
       "      <td>False</td>\n",
       "      <td>263831</td>\n",
       "      <td>B</td>\n",
       "      <td>Mid</td>\n",
       "      <td>Animals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>1996</td>\n",
       "      <td>5-263902-A-36.wav</td>\n",
       "      <td>5</td>\n",
       "      <td>36</td>\n",
       "      <td>vacuum_cleaner</td>\n",
       "      <td>False</td>\n",
       "      <td>263902</td>\n",
       "      <td>A</td>\n",
       "      <td>Periodic</td>\n",
       "      <td>Domestic sounds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>1997</td>\n",
       "      <td>5-51149-A-25.wav</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>footsteps</td>\n",
       "      <td>False</td>\n",
       "      <td>51149</td>\n",
       "      <td>A</td>\n",
       "      <td>Mid</td>\n",
       "      <td>Human sounds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>1998</td>\n",
       "      <td>5-61635-A-8.wav</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>sheep</td>\n",
       "      <td>False</td>\n",
       "      <td>61635</td>\n",
       "      <td>A</td>\n",
       "      <td>Periodic</td>\n",
       "      <td>Animals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>1999</td>\n",
       "      <td>5-9032-A-0.wav</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>dog</td>\n",
       "      <td>True</td>\n",
       "      <td>9032</td>\n",
       "      <td>A</td>\n",
       "      <td>Mid</td>\n",
       "      <td>Animals</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index           filename  fold  target        category  esc10  src_file  \\\n",
       "0     1600   5-103415-A-2.wav     5       2             pig  False    103415   \n",
       "1     1601   5-103416-A-2.wav     5       2             pig  False    103416   \n",
       "2     1602   5-103418-A-2.wav     5       2             pig  False    103418   \n",
       "3     1603   5-103420-A-2.wav     5       2             pig  False    103420   \n",
       "4     1604   5-103421-A-2.wav     5       2             pig  False    103421   \n",
       "..     ...                ...   ...     ...             ...    ...       ...   \n",
       "395   1995   5-263831-B-6.wav     5       6             hen  False    263831   \n",
       "396   1996  5-263902-A-36.wav     5      36  vacuum_cleaner  False    263902   \n",
       "397   1997   5-51149-A-25.wav     5      25       footsteps  False     51149   \n",
       "398   1998    5-61635-A-8.wav     5       8           sheep  False     61635   \n",
       "399   1999     5-9032-A-0.wav     5       0             dog   True      9032   \n",
       "\n",
       "    take event_type       superclass  \n",
       "0      A        Mid          Animals  \n",
       "1      A        Mid          Animals  \n",
       "2      A        Mid          Animals  \n",
       "3      A        Mid          Animals  \n",
       "4      A        Mid          Animals  \n",
       "..   ...        ...              ...  \n",
       "395    B        Mid          Animals  \n",
       "396    A   Periodic  Domestic sounds  \n",
       "397    A        Mid     Human sounds  \n",
       "398    A   Periodic          Animals  \n",
       "399    A        Mid          Animals  \n",
       "\n",
       "[400 rows x 10 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_type_map = {\n",
    "    # Quick Events\n",
    "    'sneezing': 'Quick',\n",
    "    'mouse_click': 'Quick',\n",
    "    'glass_breaking': 'Quick',\n",
    "    'can_opening': 'Quick',\n",
    "    'door_wood_knock': 'Quick',\n",
    "    'clock_alarm': 'Quick',\n",
    "    'hand_saw': 'Quick',\n",
    "\n",
    "    # Mid Events\n",
    "    'dog': 'Mid',\n",
    "    'cat': 'Mid',\n",
    "    'cow': 'Mid',\n",
    "    'crying_baby': 'Mid',\n",
    "    'clapping': 'Mid',\n",
    "    'coughing': 'Mid',\n",
    "    'footsteps': 'Mid',\n",
    "    'laughing': 'Mid',\n",
    "    'brushing_teeth': 'Mid',\n",
    "    'drinking_sipping': 'Mid',\n",
    "    'pig': 'Mid',\n",
    "    'rooster': 'Mid',\n",
    "    'door_wood_creaks': 'Mid',\n",
    "    'snoring': 'Mid',\n",
    "    'frog': 'Mid',\n",
    "    'hen': 'Mid',\n",
    "    'crow': 'Mid',\n",
    "    'fireworks': 'Mid',\n",
    "    'airplane': 'Mid',\n",
    "    'train': 'Mid',\n",
    "    'car_horn': 'Mid',\n",
    "    'engine': 'Mid',\n",
    "    'church_bells': 'Mid',\n",
    "\n",
    "    # Periodic Events\n",
    "    'clock_tick': 'Periodic',\n",
    "    'rain': 'Periodic',\n",
    "    'sea_waves': 'Periodic',\n",
    "    'crackling_fire': 'Periodic',\n",
    "    'crickets': 'Periodic',\n",
    "    'chirping_birds': 'Periodic',\n",
    "    'water_drops': 'Periodic',\n",
    "    'wind': 'Periodic',\n",
    "    'pouring_water': 'Periodic',\n",
    "    'thunderstorm': 'Periodic',\n",
    "    'vacuum_cleaner': 'Periodic',\n",
    "    'washing_machine': 'Periodic',\n",
    "    'keyboard_typing': 'Periodic',\n",
    "    'insects': 'Periodic',\n",
    "    'chainsaw': 'Periodic',\n",
    "    'helicopter': 'Periodic',\n",
    "    'sheep': 'Periodic',\n",
    "}\n",
    "\n",
    "superclass_map = {\n",
    "    # 🐾 Animals\n",
    "    'dog': 'Animals',\n",
    "    'rooster': 'Animals',\n",
    "    'pig': 'Animals',\n",
    "    'cow': 'Animals',\n",
    "    'frog': 'Animals',\n",
    "    'cat': 'Animals',\n",
    "    'hen': 'Animals',\n",
    "    'insects': 'Animals',\n",
    "    'sheep': 'Animals',\n",
    "    'crow': 'Animals',\n",
    "\n",
    "    # 🌿 Natural sounds\n",
    "    'rain': 'Natural sounds',\n",
    "    'sea_waves': 'Natural sounds',\n",
    "    'crackling_fire': 'Natural sounds',\n",
    "    'crickets': 'Natural sounds',\n",
    "    'chirping_birds': 'Natural sounds',\n",
    "    'water_drops': 'Natural sounds',\n",
    "    'wind': 'Natural sounds',\n",
    "    'pouring_water': 'Natural sounds',\n",
    "    'toilet_flush': 'Natural sounds',\n",
    "    'thunderstorm': 'Natural sounds',\n",
    "\n",
    "    # 🗣️ Human sounds\n",
    "    'crying_baby': 'Human sounds',\n",
    "    'sneezing': 'Human sounds',\n",
    "    'clapping': 'Human sounds',\n",
    "    'breathing': 'Human sounds',\n",
    "    'coughing': 'Human sounds',\n",
    "    'footsteps': 'Human sounds',\n",
    "    'laughing': 'Human sounds',\n",
    "    'brushing_teeth': 'Human sounds',\n",
    "    'snoring': 'Human sounds',\n",
    "    'drinking_sipping': 'Human sounds',\n",
    "\n",
    "    # 🏠 Domestic sounds\n",
    "    'door_wood_knock': 'Domestic sounds',\n",
    "    'mouse_click': 'Domestic sounds',\n",
    "    'keyboard_typing': 'Domestic sounds',\n",
    "    'door_wood_creaks': 'Domestic sounds',\n",
    "    'can_opening': 'Domestic sounds',\n",
    "    'washing_machine': 'Domestic sounds',\n",
    "    'vacuum_cleaner': 'Domestic sounds',\n",
    "    'clock_alarm': 'Domestic sounds',\n",
    "    'clock_tick': 'Domestic sounds',\n",
    "    'glass_breaking': 'Domestic sounds',\n",
    "\n",
    "    # 🚨 Urban sounds\n",
    "    'helicopter': 'Urban sounds',\n",
    "    'chainsaw': 'Urban sounds',\n",
    "    'siren': 'Urban sounds',\n",
    "    'car_horn': 'Urban sounds',\n",
    "    'engine': 'Urban sounds',\n",
    "    'train': 'Urban sounds',\n",
    "    'church_bells': 'Urban sounds',\n",
    "    'airplane': 'Urban sounds',\n",
    "    'fireworks': 'Urban sounds',\n",
    "    'hand_saw': 'Urban sounds'\n",
    "}\n",
    "\n",
    "test_df['event_type'] = test_df['category'].map(event_type_map)\n",
    "test_df['superclass'] = test_df['category'].map(superclass_map)\n",
    "test_df = test_df.reset_index()\n",
    "test_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "93e1ce6d-1015-4db5-891f-99bafcf50c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from numpy.linalg import eigh, svd\n",
    "\n",
    "def classical_mds(D, n_components=10):\n",
    "    \"\"\"\n",
    "    Classical (metric) MDS: dato D (NxN) di distanze euclidee, \n",
    "    ritorna coordinate Nxk. Equivalente a PCA su matrice di Gram.\n",
    "    \"\"\"\n",
    "    # D deve essere euclidea metrica (qui la calcoliamo noi)\n",
    "    D2 = D ** 2\n",
    "    n = D.shape[0]\n",
    "    J = np.eye(n) - np.ones((n, n)) / n\n",
    "    B = -0.5 * J @ D2 @ J  # double-centering\n",
    "\n",
    "    # autovalori/vettori (prendiamo i top k)\n",
    "    # eigh: simmetrica, ordina crescente → prendiamo la coda\n",
    "    vals, vecs = eigh(B)\n",
    "    idx = np.argsort(vals)[::-1]  # decrescente\n",
    "    vals = vals[idx]\n",
    "    vecs = vecs[:, idx]\n",
    "\n",
    "    # tieni solo i positivi (numerica-mente robusto)\n",
    "    pos = vals > 1e-12\n",
    "    vals = vals[pos]\n",
    "    vecs = vecs[:, pos]\n",
    "\n",
    "    k = min(n_components, len(vals))\n",
    "    L = np.diag(np.sqrt(vals[:k]))\n",
    "    V = vecs[:, :k]\n",
    "    X = V @ L   # Nxk\n",
    "    return X\n",
    "\n",
    "def procrustes_noscale(X, Y_ref):\n",
    "    \"\"\"\n",
    "    Procrustes allineando X a Y_ref con sola traslazione+rotazione (no scaling).\n",
    "    Restituisce X_allineata.\n",
    "    \"\"\"\n",
    "    # centra entrambi\n",
    "    Xc = X - X.mean(axis=0, keepdims=True)\n",
    "    Yc = Y_ref - Y_ref.mean(axis=0, keepdims=True)\n",
    "\n",
    "    # rotazione ortogonale via SVD (Orthogonal Procrustes, senza scala)\n",
    "    # risolve min || Xc R - Yc || con R ortogonale\n",
    "    U, _, Vt = svd(Xc.T @ Yc, full_matrices=False)\n",
    "    R = U @ Vt  # rotazione\n",
    "\n",
    "    X_aligned = Xc @ R + Y_ref.mean(axis=0, keepdims=True)  # reintroduci la traslazione target\n",
    "    return X_aligned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a1b07139-1683-45c9-ba47-40eb148ce91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_distance_matrix(E_t, metric='euclid_norm'):\n",
    "    \"\"\"\n",
    "    E_t: (N, D) embedding di tutti i suoni al frame t (tutti gli stream concatenati).\n",
    "    metric: 'euclid_norm' (consigliata) oppure 'cosine'\n",
    "    \"\"\"\n",
    "    if metric == 'euclid_norm':\n",
    "        # L2-normalizza per riga → Euclidea su vettori unitari\n",
    "        norms = np.linalg.norm(E_t, axis=1, keepdims=True) + 1e-12\n",
    "        Z = E_t / norms\n",
    "        D = pairwise_distances(Z, metric='euclidean')\n",
    "    elif metric == 'cosine':\n",
    "        D = pairwise_distances(E_t, metric='cosine')\n",
    "    else:\n",
    "        raise ValueError(\"metric deve essere 'euclid_norm' o 'cosine'\")\n",
    "    return D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b8c16f9b-164f-4e93-9f36-78356357ec28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 498/498 [01:47<00:00,  4.62it/s]\n",
      "100%|██████████| 498/498 [00:00<00:00, 2246.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coords2: (400, 498, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tqdm import tqdm\n",
    "N, T, D = embeddings_all_sounds.shape\n",
    "\n",
    "metric = 'cosine'      # euclid_norm oppure 'cosine'\n",
    "k_mds  = 20                 # \"max n dimensions per fare la procrustes\" (10 è un buon compromesso)\n",
    "ref_t  = 100                # frame di riferimento (peak F1)\n",
    "\n",
    "# 1) MDS per ogni frame\n",
    "coords_all = []\n",
    "for t in tqdm(range(T)):\n",
    "    E_t = embeddings_all_sounds[:, t, :]    # (N, D)\n",
    "    D_t = frame_distance_matrix(E_t, metric=metric)\n",
    "    X_t = classical_mds(D_t, n_components=k_mds)  # (N, k_mds)\n",
    "    coords_all.append(X_t)\n",
    "coords_all = np.stack(coords_all, axis=1)   # (N, T, k_mds)\n",
    "\n",
    "# 2) Procrustes (no scaling) verso il frame di riferimento\n",
    "X_ref = coords_all[:, ref_t, :]             # (N, k_mds)\n",
    "coords_aligned = np.empty_like(coords_all)\n",
    "for t in tqdm(range(T)):\n",
    "    coords_aligned[:, t, :] = procrustes_noscale(coords_all[:, t, :], X_ref)\n",
    "\n",
    "# 3) Prendi solo le prime 2 dimensioni per visualizzazione\n",
    "coords2 = coords_aligned[:, :, :2]          # (N, T, 2)\n",
    "print(\"coords2:\", coords2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eb72e279-5ed6-4c93-a9ed-c526805a49bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import numpy as np\n",
    "\n",
    "# === Color setup (Superclass colors) ===\n",
    "superclasses = test_df['superclass'].values\n",
    "uniq_super = np.unique(superclasses)\n",
    "cmap = plt.cm.get_cmap('tab10', len(uniq_super))\n",
    "color_map = {c:i for i,c in enumerate(uniq_super)}\n",
    "colors = np.array([color_map[c] for c in superclasses])\n",
    "\n",
    "# === Plot limits ===\n",
    "xmin, xmax = coords2[:,:,0].min(), coords2[:,:,0].max()\n",
    "ymin, ymax = coords2[:,:,1].min(), coords2[:,:,1].max()\n",
    "padx = 0.05*(xmax-xmin+1e-8)\n",
    "pady = 0.05*(ymax-ymin+1e-8)\n",
    "\n",
    "# === Figure ===\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "scat = ax.scatter(coords2[:,0,0], coords2[:,0,1],\n",
    "                  c=colors, cmap=cmap, s=24, edgecolors='k', linewidths=0.3)\n",
    "texts = []\n",
    "\n",
    "ax.set_xlim(xmin-padx, xmax+padx)\n",
    "ax.set_ylim(ymin-pady, ymax+pady)\n",
    "ax.set_xlabel(\"MDS-1\")\n",
    "ax.set_ylabel(\"MDS-2\")\n",
    "ax.set_title(f\"MDS (cosine) + Procrustes @ref {ref_t} — time 0\")\n",
    "\n",
    "# === Legend ===\n",
    "handles = [plt.Line2D([0],[0], marker='o', color='w', label=c,\n",
    "                      markerfacecolor=cmap(i), markersize=8)\n",
    "           for i, c in enumerate(uniq_super)]\n",
    "ax.legend(handles=handles, title=\"Superclass\", loc=\"upper right\", fontsize=7)\n",
    "\n",
    "categories = test_df['category'].values\n",
    "label_step = 4   # Show one label every 6 sounds\n",
    "\n",
    "# === Frame sequence ===\n",
    "frames_slow = list(range(0, 100, 2))      # first 100 frames slow\n",
    "frames_fast = list(range(100, T, 8))      # rest faster\n",
    "frames = frames_slow + frames_fast        # combine\n",
    "\n",
    "# === Update function ===\n",
    "def update(t):\n",
    "    scat.set_offsets(coords2[:, t, :])\n",
    "    global texts\n",
    "    for txt in texts:\n",
    "        txt.remove()\n",
    "    texts = []\n",
    "\n",
    "    for i, cat in enumerate(categories):\n",
    "        if i % label_step == 0:\n",
    "            txt = ax.text(coords2[i, t, 0], coords2[i, t, 1],\n",
    "                          cat, fontsize=6, ha='right', va='center', alpha=0.8)\n",
    "            texts.append(txt)\n",
    "\n",
    "    ax.set_title(f\"MDS (euclidean) + Procrustes @ref {ref_t} — frame {t}/{T-1}\")\n",
    "    return [scat] + texts\n",
    "\n",
    "# === Variable speed: custom frame generator ===\n",
    "class VariableSpeedAnimation(animation.FuncAnimation):\n",
    "    def __init__(self, fig, func, frames, **kwargs):\n",
    "        self.frame_intervals = []\n",
    "        for f in frames:\n",
    "            if f < 100:\n",
    "                self.frame_intervals.append(1000)  # slow (~3x slower)\n",
    "            else:\n",
    "                self.frame_intervals.append(180)   # default speed\n",
    "        self._counter = 0\n",
    "        super().__init__(fig, func, frames=frames, interval=self.frame_intervals[0], **kwargs)\n",
    "    \n",
    "    def _step(self, *args):\n",
    "        result = super()._step(*args)\n",
    "        if self.event_source and self._counter < len(self.frame_intervals):\n",
    "            self.event_source.interval = self.frame_intervals[self._counter]\n",
    "        self._counter += 1\n",
    "        return result\n",
    "\n",
    "# === Animation ===\n",
    "ani = VariableSpeedAnimation(fig, update, frames=frames, blit=False)\n",
    "\n",
    "save_path = 'C:/Users/P70070004/Desktop/NaturalSoundsAnalysis/Causal-SemDNN/CRNN_oneSpectBuffer/Demo_Evaluate_networks/Results_Marseille25/'\n",
    "# MP4 gives you play/pause control in any video viewer\n",
    "\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "ani.save(\n",
    "    save_path+ \"mds_procrustes_concatenation_cosine_slowstart_20_40_80.avi\",\n",
    "    writer=\"ffmpeg\",  \n",
    "    fps=10,\n",
    "    dpi=150\n",
    ")\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "74284acd-7ff8-493d-a28d-667ecea6ae3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['airplane', 'breathing', 'brushing_teeth', 'can_opening',\n",
       "       'car_horn', 'cat', 'chainsaw', 'chirping_birds', 'church_bells',\n",
       "       'clapping', 'clock_alarm', 'clock_tick', 'coughing', 'cow',\n",
       "       'crackling_fire', 'crickets', 'crow', 'crying_baby', 'dog',\n",
       "       'door_wood_creaks', 'door_wood_knock', 'drinking_sipping',\n",
       "       'engine', 'fireworks', 'footsteps', 'frog', 'glass_breaking',\n",
       "       'hand_saw', 'helicopter', 'hen', 'insects', 'keyboard_typing',\n",
       "       'laughing', 'mouse_click', 'pig', 'pouring_water', 'rain',\n",
       "       'rooster', 'sea_waves', 'sheep', 'siren', 'sneezing', 'snoring',\n",
       "       'thunderstorm', 'toilet_flush', 'train', 'vacuum_cleaner',\n",
       "       'washing_machine', 'water_drops', 'wind'], dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SET THIS to your probs array (N sounds, T frames, 50 classes)\n",
    "probs_all_sounds = embeddings_all_sounds   # ← change if your var has a different name\n",
    "N, T, C = probs_all_sounds.shape\n",
    "class_names = np.unique(test_df['category'])\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "20623d6c-2d72-4d3d-b2bb-eb88a569ea61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MDS frames: 100%|██████████| 498/498 [02:27<00:00,  3.39it/s]\n",
      "Procrustes align: 100%|██████████| 498/498 [00:00<00:00, 2871.05it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from numpy.linalg import eigh, svd\n",
    "\n",
    "def classical_mds(D, n_components=10):\n",
    "    D2 = D**2\n",
    "    n = D.shape[0]\n",
    "    J = np.eye(n) - np.ones((n, n))/n\n",
    "    B = -0.5 * J @ D2 @ J\n",
    "    vals, vecs = eigh(B)\n",
    "    idx = np.argsort(vals)[::-1]\n",
    "    vals, vecs = vals[idx], vecs[:, idx]\n",
    "    pos = vals > 1e-12\n",
    "    vals, vecs = vals[pos], vecs[:, pos]\n",
    "    k = min(n_components, len(vals))\n",
    "    return vecs[:, :k] @ np.diag(np.sqrt(vals[:k]))\n",
    "\n",
    "def procrustes_noscale(X, Y_ref):\n",
    "    Xc = X - X.mean(axis=0, keepdims=True)\n",
    "    Yc = Y_ref - Y_ref.mean(axis=0, keepdims=True)\n",
    "    U, _, Vt = svd(Xc.T @ Yc, full_matrices=False)\n",
    "    R = U @ Vt\n",
    "    return Xc @ R + Y_ref.mean(axis=0, keepdims=True)\n",
    "from tqdm import tqdm\n",
    "\n",
    "metric = 'cosine'      # or 'euclidean'\n",
    "k_mds  = 10\n",
    "ref_t  = 177           # Bruno asked to align to peak F1 frame\n",
    "\n",
    "I50 = np.eye(50, dtype=float)\n",
    "\n",
    "coords_all = []  # list of (N+50, k_mds)\n",
    "for t in tqdm(range(T), desc=\"MDS frames\"):\n",
    "    P_t = probs_all_sounds[:, t, :]           # (N, 50)\n",
    "    X_t = np.vstack([P_t, I50])               # (N+50, 50)\n",
    "    D_t = pairwise_distances(X_t, metric=metric)\n",
    "    Y_t = classical_mds(D_t, n_components=k_mds)\n",
    "    coords_all.append(Y_t)\n",
    "\n",
    "coords_all = np.stack(coords_all, axis=1)     # (N+50, T, k_mds)\n",
    "\n",
    "# Procrustes (no scaling) to ref frame\n",
    "Y_ref = coords_all[:, ref_t, :]               # (N+50, k_mds)\n",
    "coords_aligned = np.empty_like(coords_all)\n",
    "for t in tqdm(range(T), desc=\"Procrustes align\"):\n",
    "    coords_aligned[:, t, :] = procrustes_noscale(coords_all[:, t, :], Y_ref)\n",
    "\n",
    "# Take first 2 dims for viz\n",
    "coords2 = coords_aligned[:, :, :2]            # (N+50, T, 2)\n",
    "sound_idx = np.arange(N)                      # 0..N-1\n",
    "label_idx = np.arange(N, N+50)                # N..N+49\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bed106f0-88ee-413c-a369-3906a84bde4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import numpy as np\n",
    "\n",
    "# --- CONFIG ---\n",
    "num_sound_labels = 60        # how many of the 400 sounds to label (tune this)\n",
    "sound_label_strategy = \"stratified\"  # \"every_k\", \"random\", or \"stratified\"\n",
    "every_k = 7                  # if strategy == \"every_k\", label every k-th sound\n",
    "sound_label_fontsize = 6\n",
    "class_label_fontsize = 7\n",
    "\n",
    "# Colors for sounds (by superclass)\n",
    "superclasses = test_df['superclass'].values     # shape (N,)\n",
    "uniq_super = np.unique(superclasses)\n",
    "cmap = plt.cm.get_cmap('tab10', len(uniq_super))\n",
    "super_to_i = {c:i for i,c in enumerate(uniq_super)}\n",
    "sound_colors = np.array([super_to_i[c] for c in superclasses])\n",
    "\n",
    "# Select which sounds to label (indices in 0..N-1)\n",
    "rng = np.random.RandomState(42)\n",
    "if sound_label_strategy == \"every_k\":\n",
    "    sound_label_indices = np.arange(0, N, every_k)\n",
    "elif sound_label_strategy == \"random\":\n",
    "    sound_label_indices = rng.choice(np.arange(N), size=min(num_sound_labels, N), replace=False)\n",
    "elif sound_label_strategy == \"stratified\":\n",
    "    # roughly balance across superclasses\n",
    "    per_class = max(1, num_sound_labels // max(1, len(uniq_super)))\n",
    "    idxs = []\n",
    "    for sup in uniq_super:\n",
    "        pool = np.where(superclasses == sup)[0]\n",
    "        take = min(per_class, len(pool))\n",
    "        if take > 0:\n",
    "            idxs.append(rng.choice(pool, size=take, replace=False))\n",
    "    sound_label_indices = np.concatenate(idxs) if len(idxs) else np.array([], dtype=int)\n",
    "else:\n",
    "    sound_label_indices = np.array([], dtype=int)\n",
    "sound_label_indices = np.sort(np.unique(sound_label_indices))\n",
    "\n",
    "# Category names for the 400 sounds and 50 classes\n",
    "sound_categories = test_df['category'].values   # length N\n",
    "# IMPORTANT: class_names must match the model output order 0..49\n",
    "# Provide this list from your label encoder/order:\n",
    "# class_names = your_list_of_50_class_names\n",
    "\n",
    "# Plot bounds\n",
    "xmin, xmax = coords2[:,:,0].min(), coords2[:,:,0].max()\n",
    "ymin, ymax = coords2[:,:,1].min(), coords2[:,:,1].max()\n",
    "padx = 0.05*(xmax-xmin+1e-8); pady = 0.05*(ymax-ymin+1e-8)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "sc_sounds = ax.scatter(coords2[sound_idx, 0, 0], coords2[sound_idx, 0, 1],\n",
    "                       c=sound_colors, cmap=cmap, s=24, edgecolors='k', linewidths=0.3, label=\"Sounds\")\n",
    "sc_labels = ax.scatter(coords2[label_idx, 0, 0], coords2[label_idx, 0, 1],\n",
    "                       c='none', edgecolors='black', s=70, marker='s', linewidths=1.0, label='True labels')\n",
    "\n",
    "class_texts = []\n",
    "sound_texts = []\n",
    "\n",
    "ax.set_xlim(xmin-padx, xmax+padx); ax.set_ylim(ymin-pady, ymax+pady)\n",
    "ax.set_xlabel(\"MDS-1\"); ax.set_ylabel(\"MDS-2\")\n",
    "ax.set_title(f\"Output-space MDS + Procrustes @ref {ref_t} (cosine) — time 0\")\n",
    "\n",
    "# Legend: superclasses + true label marker + sound text marker\n",
    "handles = [plt.Line2D([0],[0], marker='o', color='w',\n",
    "                      label=c, markerfacecolor=cmap(i), markersize=8)\n",
    "           for i,c in enumerate(uniq_super)]\n",
    "handles.append(plt.Line2D([0],[0], marker='s', color='k', mfc='none',\n",
    "                          label='True label (class anchor)', markersize=8))\n",
    "handles.append(plt.Line2D([0],[0], marker=None, color='black',\n",
    "                          label='Sound label (subset)', linewidth=0))\n",
    "ax.legend(handles=handles, title=\"Legend\", loc=\"upper right\", fontsize=7)\n",
    "\n",
    "def draw_class_names(t):\n",
    "    # draw labels for the 50 class squares\n",
    "    for txt in class_texts: txt.remove()\n",
    "    class_texts.clear()\n",
    "    for j in range(50):\n",
    "        x, y = coords2[N + j, t, 0], coords2[N + j, t, 1]\n",
    "        txt = ax.text(x, y, class_names[j], fontsize=class_label_fontsize,\n",
    "                      ha='left', va='center', alpha=0.95, color='black')\n",
    "        class_texts.append(txt)\n",
    "\n",
    "def draw_sound_names(t):\n",
    "    # draw labels for a subset of sounds\n",
    "    for txt in sound_texts: txt.remove()\n",
    "    sound_texts.clear()\n",
    "    for i in sound_label_indices:\n",
    "        x, y = coords2[i, t, 0], coords2[i, t, 1]\n",
    "        # color the text by superclass, or use a fixed contrasting color if you prefer\n",
    "        txt_color = cmap(sound_colors[i] / max(1, len(uniq_super)-1))\n",
    "        txt = ax.text(x, y, sound_categories[i], fontsize=sound_label_fontsize,\n",
    "                      ha='right', va='center', alpha=0.85, color=txt_color)\n",
    "        sound_texts.append(txt)\n",
    "\n",
    "def update(t):\n",
    "    sc_sounds.set_offsets(coords2[sound_idx, t, :])\n",
    "    sc_labels.set_offsets(coords2[label_idx, t, :])\n",
    "    draw_class_names(t)\n",
    "    draw_sound_names(t)\n",
    "    ax.set_title(f\"Output-space MDS + Procrustes @ref {ref_t} (cosine) — time {t}/{T-1}\")\n",
    "    return [sc_sounds, sc_labels] + class_texts + sound_texts\n",
    "\n",
    "# Frame cadence: faster after 100\n",
    "frames = list(range(0, min(100, T), 2)) + list(range(100, T, 8))\n",
    "ani = animation.FuncAnimation(fig, update, frames=frames, interval=80, blit=False)\n",
    "\n",
    "# Save MP4 so you can pause/scrub\n",
    "ani.save(save_path + \"mds_20_40_80_cosine_plus_true_labels_anchors.mp4\",\n",
    "         writer=\"ffmpeg\", fps=10, dpi=150)\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9dc6f6-0137-47bd-ac8a-8491724ff542",
   "metadata": {},
   "source": [
    "This is for concatenation layer analysis one-by-one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a223b8c7-26b2-4143-a849-dd877667897a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddings_all_sounds_concatenate_248 = embeddings_all_sounds\n",
    "#embeddings_all_sounds_concatenate_52040 = embeddings_all_sounds\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "def extract_embeddings_for_layer(model,\n",
    "                                 target_layer_name,\n",
    "                                 files_test,\n",
    "                                 params,\n",
    "                                 buffer_sizes,\n",
    "                                 load_wav_fn=load_wav_16k_mono,\n",
    "                                 get_buffered_inputs_fn=get_buffered_inputs,\n",
    "                                 print_every=50):\n",
    "    \"\"\"\n",
    "    Extract (N, T, D) embeddings from `target_layer_name` using your existing\n",
    "    preprocessors (`load_wav_16k_mono` + `get_buffered_inputs`).\n",
    "    Returns: embeddings_all_sounds (N, T, D)\n",
    "    \"\"\"\n",
    "    # submodel for the chosen layer (exact name)\n",
    "    embedding_model = Model(inputs=model.inputs,\n",
    "                            outputs=model.get_layer(target_layer_name).output)\n",
    "\n",
    "    n_sounds = len(files_test)\n",
    "    embeddings_all_sounds = None\n",
    "    T = D = None\n",
    "\n",
    "    for i, file in enumerate(files_test):\n",
    "        wav = load_wav_fn(file)\n",
    "        inputs = get_buffered_inputs_fn(wav, params, buffer_sizes=buffer_sizes)\n",
    "        emb = embedding_model.predict(inputs, verbose=0)[0]  # (T, D)\n",
    "\n",
    "        if embeddings_all_sounds is None:\n",
    "            T, D = emb.shape\n",
    "            embeddings_all_sounds = np.zeros((n_sounds, T, D), dtype=emb.dtype)\n",
    "\n",
    "        # sanity: all files should yield same (T, D)\n",
    "        if emb.shape != (T, D):\n",
    "            raise ValueError(f\"Inconsistent shape at {file}: got {emb.shape}, expected {(T, D)}\")\n",
    "\n",
    "        embeddings_all_sounds[i] = emb\n",
    "\n",
    "        if print_every and (i % print_every == 0):\n",
    "            print(f\"Processed {i}/{n_sounds} files\")\n",
    "\n",
    "    print(f\"✅ Done. Embeddings shape: {embeddings_all_sounds.shape} (N={n_sounds}, T={T}, D={D})\")\n",
    "    return embeddings_all_sounds\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def compute_mds_procrustes_series(embeddings_all_sounds,\n",
    "                                  metric='cosine',\n",
    "                                  k_mds=20,\n",
    "                                  ref_t=100,\n",
    "                                  use_tqdm=True):\n",
    "    \"\"\"\n",
    "    embeddings_all_sounds: (N, T, D)\n",
    "    metric: 'cosine' or 'euclid_norm' (as in frame_distance_matrix)\n",
    "    k_mds: number of dims for MDS solution used for Procrustes (plot will use first 2)\n",
    "    ref_t: reference frame index for Procrustes alignment (no scaling)\n",
    "    returns: coords2 -> (N, T, 2)\n",
    "    \"\"\"\n",
    "    N, T, D = embeddings_all_sounds.shape\n",
    "\n",
    "    it = range(T)\n",
    "    if use_tqdm:\n",
    "        it = tqdm(it, desc=\"MDS per frame\")\n",
    "\n",
    "    # 1) MDS for each frame\n",
    "    coords_all = []\n",
    "    for t in it:\n",
    "        E_t = embeddings_all_sounds[:, t, :]     # (N, D)\n",
    "        D_t = frame_distance_matrix(E_t, metric=metric)\n",
    "        X_t = classical_mds(D_t, n_components=k_mds)  # (N, k_mds)\n",
    "        coords_all.append(X_t)\n",
    "    coords_all = np.stack(coords_all, axis=1)   # (N, T, k_mds)\n",
    "\n",
    "    # 2) Procrustes (no scaling) towards ref_t\n",
    "    X_ref = coords_all[:, ref_t, :]             # (N, k_mds)\n",
    "    coords_aligned = np.empty_like(coords_all)\n",
    "\n",
    "    it2 = range(T)\n",
    "    if use_tqdm:\n",
    "        it2 = tqdm(it2, desc=f\"Procrustes → ref {ref_t}\")\n",
    "\n",
    "    for t in it2:\n",
    "        coords_aligned[:, t, :] = procrustes_noscale(coords_all[:, t, :], X_ref)\n",
    "\n",
    "    # 3) First 2 dims for visualization\n",
    "    coords2 = coords_aligned[:, :, :2]          # (N, T, 2)\n",
    "    return coords2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import numpy as np\n",
    "\n",
    "def animate_coords2(coords2,\n",
    "                    test_df,\n",
    "                    ref_t,\n",
    "                    outpath=\"mds_procrustes.gif\",\n",
    "                    title_prefix=\"MDS (cosine) + Procrustes\",\n",
    "                    label_step=4,\n",
    "                    figsize=(15, 15),\n",
    "                    slow_until=100,     # frames < slow_until play slow\n",
    "                    slow_step=2,        # stride in slow part\n",
    "                    fast_step=8,        # stride after slow part\n",
    "                    slow_interval=1000, # ms between frames for slow part\n",
    "                    fast_interval=180   # ms between frames for fast part\n",
    "                   ):\n",
    "    \"\"\"\n",
    "    coords2: (N, T, 2)\n",
    "    test_df: must have columns 'superclass' and 'category' aligned to N\n",
    "    Saves GIF and returns the path.\n",
    "    \"\"\"\n",
    "    N, T, _ = coords2.shape\n",
    "\n",
    "    # Colors by superclass\n",
    "    superclasses = test_df['superclass'].values\n",
    "    uniq_super = np.unique(superclasses)\n",
    "    cmap = plt.cm.get_cmap('tab10', len(uniq_super))\n",
    "    sup2i = {c:i for i,c in enumerate(uniq_super)}\n",
    "    colors = np.array([sup2i[c] for c in superclasses])\n",
    "\n",
    "    # Fixed bounds\n",
    "    xmin, xmax = coords2[:,:,0].min(), coords2[:,:,0].max()\n",
    "    ymin, ymax = coords2[:,:,1].min(), coords2[:,:,1].max()\n",
    "    padx = 0.05*(xmax-xmin+1e-8)\n",
    "    pady = 0.05*(ymax-ymin+1e-8)\n",
    "\n",
    "    # Figure\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    scat = ax.scatter(coords2[:,0,0], coords2[:,0,1],\n",
    "                      c=colors, cmap=cmap, s=24, edgecolors='k', linewidths=0.3)\n",
    "    texts = []\n",
    "\n",
    "    ax.set_xlim(xmin-padx, xmax+padx)\n",
    "    ax.set_ylim(ymin-pady, ymax+pady)\n",
    "    ax.set_xlabel(\"MDS-1\")\n",
    "    ax.set_ylabel(\"MDS-2\")\n",
    "    ax.set_title(f\"{title_prefix} @ref {ref_t} — time 0\")\n",
    "\n",
    "    # Legend\n",
    "    handles = [plt.Line2D([0],[0], marker='o', color='w', label=c,\n",
    "                          markerfacecolor=cmap(i), markersize=8)\n",
    "               for i, c in enumerate(uniq_super)]\n",
    "    ax.legend(handles=handles, title=\"Superclass\", loc=\"upper right\", fontsize=7)\n",
    "\n",
    "    categories = test_df['category'].values\n",
    "\n",
    "    def update(t):\n",
    "        scat.set_offsets(coords2[:, t, :])\n",
    "        nonlocal texts\n",
    "        for txt in texts:\n",
    "            txt.remove()\n",
    "        texts = []\n",
    "        for i, cat in enumerate(categories):\n",
    "            if i % label_step == 0:\n",
    "                txt = ax.text(coords2[i, t, 0], coords2[i, t, 1],\n",
    "                              cat, fontsize=6, ha='right', va='center', alpha=0.8)\n",
    "                texts.append(txt)\n",
    "        ax.set_title(f\"{title_prefix} @ref {ref_t} — frame {t}/{T-1}\")\n",
    "        return [scat] + texts\n",
    "\n",
    "    # Frame schedule (slow then fast)\n",
    "    frames_slow = list(range(0, min(slow_until, T), slow_step))\n",
    "    frames_fast = list(range(min(slow_until, T), T, fast_step))\n",
    "    frames = frames_slow + frames_fast\n",
    "\n",
    "    # Variable-speed animation\n",
    "    class VariableSpeedAnimation(animation.FuncAnimation):\n",
    "        def __init__(self, fig, func, frames, **kwargs):\n",
    "            self.frame_intervals = []\n",
    "            for f in frames:\n",
    "                if f < slow_until:\n",
    "                    self.frame_intervals.append(slow_interval)\n",
    "                else:\n",
    "                    self.frame_intervals.append(fast_interval)\n",
    "            self._counter = 0\n",
    "            super().__init__(fig, func, frames=frames, interval=self.frame_intervals[0], **kwargs)\n",
    "        def _step(self, *args):\n",
    "            result = super()._step(*args)\n",
    "            if self.event_source and self._counter < len(self.frame_intervals):\n",
    "                self.event_source.interval = self.frame_intervals[self._counter]\n",
    "            self._counter += 1\n",
    "            return result\n",
    "\n",
    "    ani = VariableSpeedAnimation(fig, update, frames=frames, blit=False)\n",
    "    ani.save(outpath, writer=\"pillow\", fps=10)\n",
    "    plt.show()\n",
    "    return outpath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b750ff30-8a32-48ac-b79d-3daf8b66d7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 0) Split in 3 stream dal layer concatenato ====\n",
    "def split_streams(emb_all):\n",
    "    \"\"\"\n",
    "    emb_all: (N, T, Dtot) con Dtot multiplo di 3\n",
    "    return: dict {\"fast\": (N,T,Ds), \"mid\": (N,T,Ds), \"slow\": (N,T,Ds)}\n",
    "    \"\"\"\n",
    "    N, T, Dtot = emb_all.shape\n",
    "    Ds = Dtot // 3\n",
    "    return {\n",
    "        \"fast\": emb_all[:, :, 0:Ds],\n",
    "        \"mid\" : emb_all[:, :, Ds:2*Ds],\n",
    "        \"slow\": emb_all[:, :, 2*Ds:3*Ds],\n",
    "    }\n",
    "\n",
    "# ==== 1) MDS+Procrustes (no scaling) per UNO stream ====\n",
    "def mds_procrustes_single_stream(emb_stream, metric='cosine', k_mds=20, ref_t=100, use_tqdm=True):\n",
    "    \"\"\"\n",
    "    emb_stream: (N, T, Ds)\n",
    "    ritorna coords2: (N, T, 2) per quello stream\n",
    "    \"\"\"\n",
    "    return compute_mds_procrustes_series(\n",
    "        embeddings_all_sounds=emb_stream,\n",
    "        metric=metric,\n",
    "        k_mds=k_mds,\n",
    "        ref_t=ref_t,\n",
    "        use_tqdm=use_tqdm\n",
    "    )\n",
    "\n",
    "# ==== 2) MDS+Procrustes per TUTTI e 3 gli stream ====\n",
    "def mds_all_streams(emb_all, metric='cosine', k_mds=20, ref_t=100, use_tqdm=True):\n",
    "    \"\"\"\n",
    "    emb_all: (N, T, Dtot concatenato)\n",
    "    return: dict {\"fast\": (N,T,2), \"mid\": (N,T,2), \"slow\": (N,T,2)}\n",
    "    \"\"\"\n",
    "    streams = split_streams(emb_all)\n",
    "    coords = {}\n",
    "    for name, E in streams.items():\n",
    "        print(f\"[MDS] stream={name}  shape={E.shape}  metric={metric}  ref_t={ref_t}\")\n",
    "        coords[name] = mds_procrustes_single_stream(\n",
    "            emb_stream=E, metric=metric, k_mds=k_mds, ref_t=ref_t, use_tqdm=use_tqdm\n",
    "        )\n",
    "    return coords\n",
    "\n",
    "# ==== 3) GIF a 3 pannelli (MDS per stream), colori=superclass, etichette sparse=category ====\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import numpy as np\n",
    "\n",
    "def animate_three_streams_mds(coords_dict,\n",
    "                              test_df,\n",
    "                              ref_t,\n",
    "                              outpath=\"mds_three_streams.gif\",\n",
    "                              title_prefix=\"MDS (cosine) + Procrustes\",\n",
    "                              label_every=8,\n",
    "                              figsize=(24,8),\n",
    "                              slow_until=100, slow_step=2,\n",
    "                              fast_step=8,\n",
    "                              slow_interval=800, fast_interval=120):\n",
    "    \"\"\"\n",
    "    coords_dict: {\"fast\":(N,T,2), \"mid\":(N,T,2), \"slow\":(N,T,2)}\n",
    "    test_df: deve avere colonne 'superclass' e 'category' allineate ai N suoni\n",
    "    \"\"\"\n",
    "    order = [\"fast\",\"mid\",\"slow\"]\n",
    "    Xs = [coords_dict[k] for k in order]\n",
    "    N, T, _ = Xs[0].shape\n",
    "\n",
    "    # colori per superclass\n",
    "    superclasses = test_df['superclass'].values\n",
    "    uniq_super = np.unique(superclasses)\n",
    "    cmap = plt.cm.get_cmap('tab10', len(uniq_super))\n",
    "    sup2i = {c:i for i,c in enumerate(uniq_super)}\n",
    "    colors = np.array([sup2i[c] for c in superclasses])\n",
    "    cats = test_df['category'].values\n",
    "\n",
    "    # limiti comuni\n",
    "    xmin = min(X[:,:,0].min() for X in Xs); xmax = max(X[:,:,0].max() for X in Xs)\n",
    "    ymin = min(X[:,:,1].min() for X in Xs); ymax = max(X[:,:,1].max() for X in Xs)\n",
    "    padx = 0.05*(xmax-xmin+1e-8); pady = 0.05*(ymax-ymin+1e-8)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=figsize, sharex=True, sharey=True)\n",
    "    scatters, text_lists = [], []\n",
    "    for ax, name, X in zip(axes, order, Xs):\n",
    "        sc = ax.scatter(X[:,0,0], X[:,0,1], c=colors, cmap=cmap, s=30,\n",
    "                        edgecolors='k', linewidths=0.3)\n",
    "        scatters.append(sc)\n",
    "        text_lists.append([])\n",
    "        ax.set_xlim(xmin-padx, xmax+padx)\n",
    "        ax.set_ylim(ymin-pady, ymax+pady)\n",
    "        ax.set_title(f\"{name} — t=0\")\n",
    "        ax.set_xlabel(\"MDS-1\")\n",
    "    axes[0].set_ylabel(\"MDS-2\")\n",
    "\n",
    "    # legenda\n",
    "    handles = [plt.Line2D([0],[0], marker='o', color='w', label=c,\n",
    "                          markerfacecolor=cmap(i), markersize=8)\n",
    "               for i,c in enumerate(uniq_super)]\n",
    "    axes[-1].legend(handles=handles, title=\"Superclass\", fontsize=7, loc=\"upper right\")\n",
    "\n",
    "    # frames: lenti poi veloci\n",
    "    frames_slow = list(range(0, min(slow_until, T), slow_step))\n",
    "    frames_fast = list(range(min(slow_until, T), T, fast_step))\n",
    "    frames = frames_slow + frames_fast\n",
    "\n",
    "    def update(t):\n",
    "        for ax, sc, texts, X, name in zip(axes, scatters, text_lists, Xs, order):\n",
    "            sc.set_offsets(X[:, t, :])\n",
    "            for txt in texts: txt.remove()\n",
    "            texts.clear()\n",
    "            for i, cat in enumerate(cats):\n",
    "                if i % label_every == 0:\n",
    "                    txt = ax.text(X[i, t, 0], X[i, t, 1],\n",
    "                                  cat, fontsize=6, ha='right', va='center', alpha=0.8)\n",
    "                    texts.append(txt)\n",
    "            ax.set_title(f\"{name} — frame {t}/{T-1}\")\n",
    "        fig.suptitle(f\"{title_prefix} — ref {ref_t}\", y=0.98)\n",
    "        return scatters + [txt for texts in text_lists for txt in texts]\n",
    "\n",
    "    class VariableSpeed(animation.FuncAnimation):\n",
    "        def __init__(self, fig, func, frames, **kwargs):\n",
    "            self.frame_intervals = [(slow_interval if f < slow_until else fast_interval) for f in frames]\n",
    "            self._i = 0\n",
    "            super().__init__(fig, func, frames=frames, interval=self.frame_intervals[0], **kwargs)\n",
    "        def _step(self, *args):\n",
    "            r = super()._step(*args)\n",
    "            if self.event_source and self._i < len(self.frame_intervals):\n",
    "                self.event_source.interval = self.frame_intervals[self._i]\n",
    "            self._i += 1\n",
    "            return r\n",
    "\n",
    "    ani = VariableSpeed(fig, update, frames=frames, blit=False)\n",
    "    ani.save(outpath, writer=\"pillow\", fps=10)\n",
    "    plt.show()\n",
    "    return outpath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c10138b-54e6-4b47-bb6f-fcf653896db8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embeddings_all_sounds_concatenate_248' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# embeddings_all_sounds_concatenate_248 = embeddings_all_sounds  # come da tua variabile\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m E248 \u001b[38;5;241m=\u001b[39m \u001b[43membeddings_all_sounds_concatenate_248\u001b[49m  \u001b[38;5;66;03m# (N, T, 768)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# 1) MDS+Procrustes per i tre stream\u001b[39;00m\n\u001b[0;32m      5\u001b[0m coords_streams_248 \u001b[38;5;241m=\u001b[39m mds_all_streams(\n\u001b[0;32m      6\u001b[0m     emb_all\u001b[38;5;241m=\u001b[39mE248,\n\u001b[0;32m      7\u001b[0m     metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meuclid_norm\u001b[39m\u001b[38;5;124m'\u001b[39m,   \u001b[38;5;66;03m# oppure 'euclid_norm'\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m     use_tqdm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     11\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'embeddings_all_sounds_concatenate_248' is not defined"
     ]
    }
   ],
   "source": [
    "# embeddings_all_sounds_concatenate_248 = embeddings_all_sounds  # come da tua variabile\n",
    "E248 = embeddings_all_sounds_concatenate_248  # (N, T, 768)\n",
    "\n",
    "# 1) MDS+Procrustes per i tre stream\n",
    "coords_streams_248 = mds_all_streams(\n",
    "    emb_all=E248,\n",
    "    metric='euclid_norm',   # oppure 'euclid_norm'\n",
    "    k_mds=20,\n",
    "    ref_t=100,         # oppure 177 se vuoi il peak F1 che usava Bruno\n",
    "    use_tqdm=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd829dfb-444d-49d5-9b2b-480a4526bfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) GIF 3 pannelli\n",
    "gif_248 = animate_three_streams_mds(\n",
    "    coords_dict=coords_streams_248,\n",
    "    test_df=test_df,\n",
    "    ref_t=100,\n",
    "    outpath=\"mds_three_streams_concat_euclid_248.gif\",\n",
    "    title_prefix=\"MDS (euclid) + Procrustes — stream-wise\",\n",
    "    label_every=6,\n",
    "    figsize=(15,5),\n",
    "    slow_until=100, slow_step=2,\n",
    "    fast_step=8,\n",
    "    slow_interval=600, fast_interval=120\n",
    ")\n",
    "print(\"Saved:\", gif_248)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d3f58f-9e8e-46a1-b292-2d5fac04e3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "E52040 = embeddings_all_sounds_concatenate_52040  # (N, T, 1536)\n",
    "\n",
    "coords_streams_52040 = mds_all_streams(\n",
    "    emb_all=E52040,\n",
    "    metric='euclid_norm',\n",
    "    k_mds=20,\n",
    "    ref_t=100,\n",
    "    use_tqdm=True\n",
    ")\n",
    "\n",
    "gif_52040 = animate_three_streams_mds(\n",
    "    coords_dict=coords_streams_52040,\n",
    "    test_df=test_df,\n",
    "    ref_t=100,\n",
    "    outpath=\"mds_three_streams_concatenate_euclidean_52040.gif\",\n",
    "    title_prefix=\"MDS (euclidean) + Procrustes — stream-wise\",\n",
    "    label_every=6,\n",
    "    figsize=(15,5),\n",
    "    slow_until=100, slow_step=2,\n",
    "    fast_step=8,\n",
    "    slow_interval=600, fast_interval=120\n",
    ")\n",
    "print(\"Saved:\", gif_52040)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2232f5-ffc6-4f5c-bb78-60377cf25e6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
